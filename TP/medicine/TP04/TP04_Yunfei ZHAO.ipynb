{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME4: The goal of the TME is to learn various techniques of feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFdr, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Golub dataset\n",
    "X_golub = pd.read_csv('data/Golub_X',sep=' ', header=None).to_numpy() # Observations\n",
    "y_golub = pd.read_csv('data/Golub_y',sep=' ', header=None).to_numpy()  # Classes\n",
    "y_golub = np.squeeze(y_golub, axis=1)\n",
    "X_train_golub, X_test_golub, y_train_golub, y_test_golub = train_test_split(X_golub, y_golub, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Breast Cancer dataset\n",
    "data_breast_cancer = pd.read_table('data/BreastDiagnostic.txt',sep=',',header=None)\n",
    "breast_cancer_X = data_breast_cancer.iloc[:, 2:].to_numpy()\n",
    "breast_cancer_y = data_breast_cancer.iloc[:, 1].to_numpy()\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(breast_cancer_X, breast_cancer_y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A class with different kinds of feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FS():\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        # dataset initialisation\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.new_X_train = None\n",
    "        self.new_X_test = None\n",
    "        self.model = None\n",
    "        \n",
    "    def feature_selection(self, method, param=0):\n",
    "        if method == None:\n",
    "            print(\"No feature selection\")\n",
    "            self.new_X_train = self.X_train\n",
    "            self.new_X_test = self.X_test\n",
    "            \n",
    "        if method == \"VT\":\n",
    "            print(f\"TV feature selection with threshold {param['VT_threshold']}\")\n",
    "            sel = VarianceThreshold(threshold=(param[\"VT_threshold\"]))\n",
    "            self.new_X_train = sel.fit_transform(self.X_train)\n",
    "            self.new_X_test = sel.transform(self.X_test)\n",
    "        if method == \"univariate\":\n",
    "            sel = SelectFdr(chi2, alpha=param[\"alpha\"])\n",
    "            self.new_X_train = sel.fit_transform(self.X_train, self.y_train)\n",
    "            self.new_X_test = sel.transform(self.X_test)\n",
    "\n",
    "    \n",
    "    def fit(self, model):\n",
    "        self.model = model\n",
    "        self.model.fit(self.new_X_train, self.y_train)\n",
    "        print(f\"Train score: {self.model.score(self.new_X_train, self.y_train)}\")\n",
    "    \n",
    "    def test(self):\n",
    "        print(f\"Test score: {self.model.score(self.new_X_test, self.y_test)}\")\n",
    "        \n",
    "    def get_original_feature_number(self):\n",
    "        print(f\"Original feature number: {self.X_train.shape[1]}\")\n",
    "    \n",
    "    def get_selected_feature_number(self):\n",
    "        print(f\"Selected feature number: {self.new_X_train.shape[1]}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "golub_fs = FS(X_train_golub, X_test_golub, y_train_golub, y_test_golub)\n",
    "cancer_fs = FS(X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A simple heuristic approach is to delete features whose variance is less then a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Golub dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = linear_model.LogisticRegression(random_state=0, penalty=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No feature selection\n",
      "Train score: 1.0\n",
      "Test score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# With no threshold\n",
    "golub_fs.feature_selection(method=None)\n",
    "golub_fs.fit(cls)\n",
    "golub_fs.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV feature selection with threshold 0.03\n",
      "Train score: 1.0\n",
      "Test score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# With threshold 0.03\n",
    "golub_fs.feature_selection(method=\"VT\", param={\"VT_threshold\":0.03})\n",
    "golub_fs.fit(cls)\n",
    "golub_fs.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV feature selection with threshold 0.05\n",
      "Train score: 1.0\n",
      "Test score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# With threshold 0.05\n",
    "golub_fs.feature_selection(method=\"VT\", param={\"VT_threshold\":0.05})\n",
    "golub_fs.fit(cls)\n",
    "golub_fs.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV feature selection with threshold 0.06\n",
      "Train score: 1.0\n",
      "Test score: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# With threshold 0.06\n",
    "golub_fs.feature_selection(method=\"VT\", param={\"VT_threshold\":0.06})\n",
    "golub_fs.fit(cls)\n",
    "golub_fs.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature number: 3562\n"
     ]
    }
   ],
   "source": [
    "golub_fs.get_original_feature_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature number: 120\n"
     ]
    }
   ],
   "source": [
    "golub_fs.get_selected_feature_number()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No feature selection\n",
      "Train score: 0.9516483516483516\n",
      "Test score: 0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "cancer_fs.feature_selection(method=None)\n",
    "cancer_fs.fit(cls)\n",
    "cancer_fs.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV feature selection with threshold 0.03\n",
      "Train score: 0.9538461538461539\n",
      "Test score: 0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "cancer_fs.feature_selection(method=\"VT\", param={\"VT_threshold\":0.03})\n",
    "cancer_fs.fit(cls)\n",
    "cancer_fs.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV feature selection with threshold 0.05\n",
      "Train score: 0.9384615384615385\n",
      "Test score: 0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "cancer_fs.feature_selection(method=\"VT\", param={\"VT_threshold\":0.05})\n",
    "cancer_fs.fit(cls)\n",
    "cancer_fs.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature number: 30\n"
     ]
    }
   ],
   "source": [
    "cancer_fs.get_original_feature_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature number: 12\n"
     ]
    }
   ],
   "source": [
    "cancer_fs.get_selected_feature_number()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse:\n",
    "By using this method based on variable variance, we can significantly reduce the parameters number without having a great degradation of the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Univariate feature selection \n",
    "Use statistical tests to get rid of features which are not statistically significant with respect to the vector of class.\n",
    "\n",
    "Try the SelectFdr function that computes p-values for an estimated false discovery rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For dataset golub, when we increase alpha it is easily that all features are not selected\n",
    "Maybe it is due to the fact that information on genes are too noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 1.0\n",
      "Original feature number: 3562\n",
      "Selected feature number: 3562\n"
     ]
    }
   ],
   "source": [
    "golub_fs.feature_selection(method=\"univariate\", param={\"alpha\":1})\n",
    "golub_fs.fit(cls)\n",
    "golub_fs.test()\n",
    "golub_fs.get_original_feature_number()\n",
    "golub_fs.get_selected_feature_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 1.0\n",
      "Original feature number: 3562\n",
      "Selected feature number: 3560\n"
     ]
    }
   ],
   "source": [
    "golub_fs.feature_selection(method=\"univariate\", param={\"alpha\":0.9999})\n",
    "golub_fs.fit(cls)\n",
    "golub_fs.test()\n",
    "golub_fs.get_original_feature_number() \n",
    "golub_fs.get_selected_feature_number()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For cancer dataset, we can do a feature selection with this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9516483516483516\n",
      "Test score: 0.956140350877193\n",
      "Original feature number: 30\n",
      "Selected feature number: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "cancer_fs.feature_selection(method=\"univariate\", param={\"alpha\":1})\n",
    "cancer_fs.fit(cls)\n",
    "cancer_fs.test()\n",
    "cancer_fs.get_original_feature_number() \n",
    "cancer_fs.get_selected_feature_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9428571428571428\n",
      "Test score: 0.9649122807017544\n",
      "Original feature number: 30\n",
      "Selected feature number: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "cancer_fs.feature_selection(method=\"univariate\", param={\"alpha\":0.5})\n",
    "cancer_fs.fit(cls)\n",
    "cancer_fs.test()\n",
    "cancer_fs.get_original_feature_number() \n",
    "cancer_fs.get_selected_feature_number()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. L1 -based feature selection is designed to find an optimal solution.\n",
    "The sparsity parameter is important (since it controls the number of non-zero parameters: if too many parameters\n",
    "are kept, no really feature selection; if too few parameters are chosen, it is possible that the\n",
    "accuracy is very poor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear logistic regression lasso train score:0.9824561403508771\n",
      "linear logistic regression lasso test score:1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# golub\n",
    "linear_regression_lasso = linear_model.LogisticRegression(random_state=0, penalty='l1', solver='saga', C=1)\n",
    "linear_regression_lasso.fit(X_train_golub, y_train_golub)\n",
    "print(f\"linear logistic regression lasso train score:{linear_regression_lasso.score(X_train_golub, y_train_golub)}\")\n",
    "print(f\"linear logistic regression lasso test score:{linear_regression_lasso.score(X_test_golub, y_test_golub)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7110541602046173"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_lasso.coef_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear logistic regression lasso train score:0.631578947368421\n",
      "linear logistic regression lasso test score:0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# with stronger regularization, C Like in support vector machines, smaller values specify stronger regularization.\n",
    "linear_regression_lasso = linear_model.LogisticRegression(random_state=0, penalty='l1', solver='saga', C=0.1)\n",
    "linear_regression_lasso.fit(X_train_golub, y_train_golub)\n",
    "print(f\"linear logistic regression lasso train score:{linear_regression_lasso.score(X_train_golub, y_train_golub)}\")\n",
    "print(f\"linear logistic regression lasso test score:{linear_regression_lasso.score(X_test_golub, y_test_golub)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_lasso.coef_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear logistic regression lasso train score:0.8989010989010989\n",
      "linear logistic regression lasso test score:0.9473684210526315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# cancer\n",
    "linear_regression_lasso = linear_model.LogisticRegression(random_state=0, penalty='l1', solver='saga', C=1)\n",
    "linear_regression_lasso.fit(X_train_cancer, y_train_cancer)\n",
    "print(f\"linear logistic regression lasso train score:{linear_regression_lasso.score(X_train_cancer, y_train_cancer)}\")\n",
    "print(f\"linear logistic regression lasso test score:{linear_regression_lasso.score(X_test_cancer, y_test_cancer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear logistic regression lasso train score:0.8989010989010989\n",
      "linear logistic regression lasso test score:0.9473684210526315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "linear_regression_lasso = linear_model.LogisticRegression(random_state=0, penalty='l1', solver='saga', C=0.1)\n",
    "linear_regression_lasso.fit(X_train_cancer, y_train_cancer)\n",
    "print(f\"linear logistic regression lasso train score:{linear_regression_lasso.score(X_train_cancer, y_train_cancer)}\")\n",
    "print(f\"linear logistic regression lasso test score:{linear_regression_lasso.score(X_test_cancer, y_test_cancer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(linear_regression_lasso.coef_ != 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:1.0\n",
      "test score:0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# golub\n",
    "model = LinearSVC(C=0.5, penalty=\"l1\", dual=False)\n",
    "model.fit(X_train_golub, y_train_golub)\n",
    "print(f\"train score:{model.score(X_train_golub, y_train_golub)}\")\n",
    "print(f\"test score:{model.score(X_test_golub, y_test_golub)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:0.9824561403508771\n",
      "test score:0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=0.1, penalty=\"l1\", dual=False)\n",
    "model.fit(X_train_golub, y_train_golub)\n",
    "print(f\"train score:{model.score(X_train_golub, y_train_golub)}\")\n",
    "print(f\"test score:{model.score(X_test_golub, y_test_golub)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.coef_ != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:0.9604395604395605\n",
      "test score:0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# cancer\n",
    "model = LinearSVC(C=0.5, penalty=\"l1\", dual=False)\n",
    "model.fit(X_train_cancer, y_train_cancer)\n",
    "print(f\"train score:{model.score(X_train_cancer, y_train_cancer)}\")\n",
    "print(f\"test score:{model.score(X_test_cancer, y_test_cancer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.coef_ != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:0.9516483516483516\n",
      "test score:0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=0.1, penalty=\"l1\", dual=False)\n",
    "model.fit(X_train_cancer, y_train_cancer)\n",
    "print(f\"train score:{model.score(X_train_cancer, y_train_cancer)}\")\n",
    "print(f\"test score:{model.score(X_test_cancer, y_test_cancer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.coef_ != 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:0.9824561403508771\n",
      "test score:1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# golub\n",
    "model = linear_model.LogisticRegression(random_state=0, penalty='elasticnet', C=1, l1_ratio=0.7,  solver='saga')\n",
    "model.fit(X_train_golub, y_train_golub)\n",
    "print(f\"train score:{model.score(X_train_golub, y_train_golub)}\")\n",
    "print(f\"test score:{model.score(X_test_golub, y_test_golub)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.coef_!=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:0.8989010989010989\n",
      "test score:0.9473684210526315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/AMAL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# cancet\n",
    "model = linear_model.LogisticRegression(random_state=0, penalty='elasticnet', C=1, l1_ratio=0.7,  solver='saga')\n",
    "model.fit(X_train_cancer, y_train_cancer)\n",
    "print(f\"train score:{model.score(X_train_cancer, y_train_cancer)}\")\n",
    "print(f\"test score:{model.score(X_test_cancer, y_test_cancer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.coef_!=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "I find the SVM has relatively better performance on the breast cancer dataset.\n",
    "\n",
    "two types of elastic Net has a better performance on golub dataset.\n",
    "\n",
    "I use (model.coef_ != 0).sum() to show the final selected number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ens",
   "language": "python",
   "name": "ens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

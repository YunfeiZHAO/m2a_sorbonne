# -*- coding: utf-8 -*-
"""3-a: Transfer Learning

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_RnEZX1Fp1z6seRM2c3mpHHowvDeQ1ka

# Warning : 
# To keep your modifications in case you want to come back later to this colab, do *File -> Save a copy in Drive*.

Before starting the TP, make sure that you are on a GPU environment:

Exécution -> Modifier le type d'exécution -> Accélerateur matériel = GPU
"""

import argparse
import os
import time

import PIL
from PIL import Image

import numpy as np
import torchvision
import pickle

import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.utils.data
import torchvision.datasets as datasets
import torchvision.models as models
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

"""# Part 1 : VGG16 Architecture"""

# !wget https://github.com/cdancette/deep-learning-polytech-tp6-7/raw/master/tp8/imagenet_classes.pkl
#
# # Bonus : Classifier some examples with VGG16 and comment on the results in your report.
# !wget --content-disposition https://unsplash.com/photos/gKXKBY-C-Dk/download?force=true -O cat.jpg
# !wget --content-disposition https://unsplash.com/photos/qO-PIF84Vxg/download?force=true -O dog.jpg

torch.manual_seed(0)
imagenet_classes = pickle.load(open('imagenet_classes.pkl', 'rb'))


def vgg16_simple():
    # cat = Image.open('cat.jpg')
    #dog = Image.open('dog.jpg')
    me = Image.open('photo.png')
    me.show()
    #plt.imshow(dog)
    # Add your images
    # YOUR CODE HERE for the bonus:
    vgg16 = torchvision.models.vgg16(pretrained=True)
    vgg16.eval()
    img = me
    img = img.resize((224, 224), Image.BILINEAR)

    img = np.array(img, dtype=np.float32)[:, :, 0:3] / 255
    img = img.transpose((2, 0, 1))
    # transform into a batch containing one image
    img = np.expand_dims(img, 0)
    x = torch.Tensor(img)

    t = transforms.Compose([transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                            ])
    y = vgg16(t(x))# TODO forward pass
    y = y.detach().numpy()  # transformation to array numpy
    max_classes = np.argsort(y)[0]
    c = [imagenet_classes[int(j)] for i, j in enumerate(max_classes)]
    return y, c


def vgg16_simple_feature_map():
    me = Image.open('photo.png')
    vgg16 = torchvision.models.vgg16(pretrained=True)
    vgg16.eval()
    img = me
    img = img.resize((224, 224), Image.BILINEAR)

    img = np.array(img, dtype=np.float32)[:, :, 0:3] / 255
    img = img.transpose((2, 0, 1))
    # transform into a batch containing one image
    img = np.expand_dims(img, 0)
    x = torch.Tensor(img)

    t = transforms.Compose([transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                            ])

    # Visualize feature maps
    activation = {}

    def get_activation(name):
        def hook(model, input, output):
            activation[name] = output.detach().numpy() # transformation to array numpy
        return hook

    vgg16.features[0].register_forward_hook(get_activation('conv0'))
    vgg16.features[1].register_forward_hook(get_activation('ReLU1'))
    vgg16.features[2].register_forward_hook(get_activation('conv2'))
    vgg16.features[3].register_forward_hook(get_activation('ReLU3'))
    vgg16.features[4].register_forward_hook(get_activation('maxpool4'))
    vgg16.features[28].register_forward_hook(get_activation('conv28'))

    y = vgg16(t(x))

    # convs = list(vgg16.children())
    # conv1 = list(convs[0].children())[0]
    # conv1_output = conv1(t(x)).squeeze(0)
    #
    x_len = 8
    y_len = 8
    fig, axes = plt.subplots(x_len, y_len, figsize=(10, 10))
    axes = axes.flatten()
    for i in range(x_len * y_len):
        axes[i].imshow(conv1_output.detach().permute(1, 2, 0)[:, :, i])
    plt.show()

"""# Part 2: Transfer Learning with VGG16 on 15 Scene"""

# !wget https://github.com/cdancette/deep-learning-polytech-tp6-7/raw/master/tp8/15ScenesData.zip
# !unzip 15ScenesData.zip
#
# ls 15SceneData/test/bedroom/


#     imagenet_classes = pickle.load(open('imagenet_classes.pkl', 'rb')) # chargement des classes
# class VGG16relu17:
#   pass  # TO COMPLETE
#
# PRINT_INTERVAL = 50
# CUDA = True
#
# def get_dataset(batch_size, path):
#
#     # This function allows us to copy an image 3 times and thus "transform" a
#     # black and white image with 1 channel into an RGB image with 3 channels.
#     # Use it with transform.Lambda
#     def duplicateChannel(img):
#         img = img.convert('L')
#         np_img = np.array(img, dtype=np.uint8)
#         np_img = np.dstack([np_img, np_img, np_img])
#         img = Image.fromarray(np_img, 'RGB')
#         return img
#
#     #####################
#     ## Your code here  ##
#     #####################
#     # Add pre-processing
#     train_dataset = datasets.ImageFolder(path+'/train',
#         transform=transforms.Compose([ # todo pre-processing
#             transforms.ToTensor()
#         ]))
#     val_dataset = datasets.ImageFolder(path+'/test',
#         transform=transforms.Compose([ # todo pre-processing
#             transforms.ToTensor()
#         ]))
#     ####################
#     ##      END        #
#     ####################
#
#     train_loader = torch.utils.data.DataLoader(train_dataset,
#                         batch_size=batch_size, shuffle=False, pin_memory=CUDA, num_workers=2)
#     val_loader = torch.utils.data.DataLoader(val_dataset,
#                         batch_size=batch_size, shuffle=False, pin_memory=CUDA, num_workers=2)
#
#     return train_loader, val_loader
#
# def extract_features(data, model):
#     #####################
#     ## Your code here  ##
#     #####################
#     # init features matrices
#     X = None
#     y = None
#     ####################
#     ##      END        #
#     ####################
#
#     for i, (input, target) in enumerate(data):
#         if i % PRINT_INTERVAL == 0:
#             print('Batch {0:03d}/{1:03d}'.format(i, len(data)))
#         if CUDA:
#             input = input.cuda()
#         #####################
#         ## Your code here  ##
#         #####################
#         # todo feature extraction
#         X = None
#         y = None
#         ####################
#         ##      END        #
#         ####################
#
#     return X, y
#
#
# def main(path="15SceneData", batch_size=8):
#     print('Initializing VGG16')
#     vgg16 = models.vgg16(pretrained=True)
#
#     print('Initializing VGG16relu7')
#     #####################
#     ## Your code here  ##
#     #####################
#     # Replace with a truncated network to perform feature extraction
#     # We will create a new class VGG16relu here.
#
#     model = vgg16
#     ####################
#     ##      END        #
#     ####################
#
#     model.eval()
#     if CUDA: # If we have GPU, use CUDA
#         cudnn.benchmark = True
#         model = model.cuda()
#
#     # Obtain the data
#     print('Obtaining data')
#     train, test = get_dataset(batch_size, path)
#
#     # Feature Extraction
#     print('Feature extraction')
#     X_train, y_train = extract_features(train, model)
#     X_test, y_test = extract_features(test, model)
#
#     #####################
#     ## Your code here  ##
#     #####################
#     # Training and evaluation of SVMs here
#     print('Training SVMs')
#     accuracy = 0
#     ####################
#     ##      END        #
#     ####################
#     print('Accuracy = %f' % accuracy)
#
# main("15SceneData", 8)